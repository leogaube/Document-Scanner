\documentclass[bibliography=totoc]{scrartcl}
\usepackage[ngerman, english]{babel}
\usepackage{rwukoma}
\usepackage[pdfusetitle]{hyperref}
\usepackage{lipsum,caption}
\usepackage{acronym} 

\title{Document Scanner}
\author{Leopold Gaube and Florian Betz}
\date{\today}

\begin{document}
	\maketitle
	\tableofcontents

	\clearpage

	\section{Requirements}
	There are already many document scanners on the market that can digitalize a paper or similar. 
	The quality of the document scanning depends on the used algorithms.
	To garantues a good scan, a perspective transformation should be used.
	
	A comfortable library to use computer vision functions is \ac{OpenCV}.
	\ac{OpenCV} is an open source computer vision and machine learning software library. \cite{OpenCV}
	You can use OpenCV with the programming languages C, C++, Python or Java.
	

    \section{Algorithm Overview}
	Our algorithm for scanning a document in an image consists of three main parts, each with its own challenges.
	
	First, we have to localize the document in the image. 
	Then we use a perspective transform from the corner points of the document to the entire span of the image in order to obtain a top-down view without perspective distortions.
	Finally, we use a binary filter to distinguish text from background and save the resulting image as our scanned document.

	\section{Challenges}
	It is fairly straight forward if we work with an image like in Figure 1a.
	However, we also want our algorithm to work under bad lighting conditions [Fig. 1b], taken from an extreme angle [Fig. 1c], with a document on a low contrast background [Fig. 1d].
	Of course the final image will suffer in quality compared to a document taken under near-optimal conditions, but our goal is to still obtain a readable document.
	
	\section{Document Localization}
	Some smartphone scanner apps require the user to mark the four corner points of the document manually. 
	However, we want to automate this process by detecting the corner points using Computer Vision.
	Detecting the corner points consistantly is probably the hardest and most crutial step of the entire algorithm. 
	
	The information content of any image is really high consisting of width x height x channels indiviual values, usually in the magnitude of millions of pixels.
	Our first goal is to find the document outline in the input image.
	For this step we don't need a high resolution, so we will reduce the information content by first downsizing the input image to something more manageable.
	In the process we will also get rid of noice which could potentially reduce the algorithms performance.
	We resize the image to 400 pixels on the larger side (width or height) and adjust the smaller side according to the original aspect ratio.
	
	In addition to downsizing the image, we also use a Gaussian Blur (with a 5x5 kernel) in order to smooth the image even further.
	Now we can use a Canny Edge Detector to find locally sudden changes in brightness or color. 
	The resulting binary image distinguishes between edges (depicted as white) and non-edges (black) for each pixel location in the original image.
	The Canny Edge Detector uses two thresholds: TODO explain lower/higher thresholds
	Setting low threshold values will result in more edges.
	
	We are only concerned that the document outline shows up in our edge image consistently, which is how we chose 150 for the higher threshold and 100 for the lower threshold.
	
	From this point on, we have to assume that there exists a contour in our edge image which matches the outline of our document. 
	It is ok, if we miss the exact location of the document corners by a couple of pixels, but detecting the wrong contour would make the resulting document unreadable.

	Detecting contours is easy with OpenCV using the cv2.findContours() method.
	However, we have to distinguish the one corresponding to our document from all the other contours in the image.
	Other contours may include text, graphs and pictures on the document itself or even objects e.g. a stapler on the desk. 
	The contour we are looking for should have one of the largest perimeters and it should be able to be approximated it with only four points.
	Both of these assumptions will help us to find the right one, as it is highly unprobable another contour meets both criteria. 
	We will just pick the largest contour that can be approximated using four points as show by the following pseudo code:
	
	\section{Perspective Transformation}
	For the document localization part, we have been working with a low resolution image, making the text unreadable.
	Now we want to create a top-down view of the document with readable text, so we need to project the detected corner points back onto the original resolution. 

	When detecting contours, OpenCV does not care about the order of the points which may result in a rotated image when applying the perspective transformation.
	So we first have to write a function that sorts our corner points in a consistent manner.
	The following pseudo code can be used to sort points in the following order: top left, bottom left, top right, bottom right.

	ToDo: pseudo code

	
	\section{Thresholding}
	For the last step of our project we convert the scanned document into a binary image, thus each pixel is supposed to be either black for text and graphs or white for the background.
	The easiest way to achieve this is by converting the color image into grayscale and setting a threshold value. 
	Any pixel value below this threshold would become black, pixel values above would be set to white.

	However, there is a problem with this simple thresholding approach, as it performs poorly under bad lighting conditions as can be seen in [Fig. 3a].
	When taking pictures of documents, a user may cast a shadow with their camera or mobile phone onto the document. 
	This can be problematic if a region in the shadows has lower pixel values for the background than the text in a well-lit region.
	In such a scenario, it would be impossible to find a static threshold that works well for the entire document.
	So instead we need an adaptive approach that looks at a set of neighboring pixels and chooses a threshold for this local region dynamically.

	\section{Known Problems and Possible Solutions}
	Our algorithm works quite well and consistently even under difficult lighting conditions or when the picture of the document was taken from an unusual angle.
	However, we also observed some use cases where it fails:
	
	If the document is placed on a low-contrast background (e.g. a white desk), our algorithm has problems detecting an edge where the document outline should be.
	In some cases it may already help to do more preprocessing e.g. contrast enhancement.
	Currently, our program uses the Canny Edge Detector only once with a fixed lower and upper threshold as this works best for the majority of images.
	Whenever the document localization fails, we could try to repeat the process with lower threshold. 
	This will introduce more noise in the edge image, but it might also be enough to detect the document outline.

	Another situation in which our program works poorly is with bent document corner. 
	This may break the localization algorithm, because the detected contour would - theoretically - have to be approximated using five instead of four corner points.
	In some cases with minor bent corners this still works ok, as we allow for an error of 3\% when approximating the document contour(see Fig. 4a) which may still result in a four point contour approximation. 
	The resulting image will definitely have some small distortion due to the inaccurate localization of the bent corner, but at least the algorithm does not fail entirely.
	The same problem arises if the user is not careful while taking the image and accidentally cutting off a single corner from the picture composition.
	
	For the last two problematic use cases, we already have a possible solution in mind: 
	Whenever the document localization fails, we could try a completely different approach using a Hough Transformation. 
	Hough Transformations are very good at detecting straight lines in edge images. 
	Detecting the four most prevalent lines (with maximum-supression) in an edge image, corresponds to detecting the most likely document edges.
	The intersections of any two lines give us the location of each document corner. 
	A bent/hidden corner or even a corner outside of the image composition should be less of a problem when using the Hough Transformation approach.
	Nevertheless, it has its own downside, because the most prevalent lines have to be document edges and not for instance the edge of a desk.


\section*{List of Acronyms} 
\addcontentsline{toc}{section}{List of Acronyms}

\begin{acronym}[....]
    \acro{OpenCV}{Open Source Computer Vision Library}
\end{acronym}
\bibliographystyle{alpha}			
\bibliography{literature}
\end{document}
